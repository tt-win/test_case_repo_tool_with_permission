#!/usr/bin/env python3
"""
è³‡æ–™åº«é·ç§»è…³æœ¬ - ç¾ä»£åŒ–ç‰ˆæœ¬
"""

import os
import sys
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Optional
import json

# å°‡é …ç›®æ ¹ç›®éŒ„æ·»åŠ åˆ° Python è·¯å¾‘ä¸­
sys.path.insert(0, str(Path(__file__).parent))

from sqlalchemy import create_engine, MetaData, inspect, text
from sqlalchemy.engine import Engine
from app.database import engine, DATABASE_URL
from app.models.database_models import Base

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class DatabaseMigrator:
    """è³‡æ–™åº«é·ç§»ç®¡ç†å™¨"""
    
    def __init__(self, engine: Engine):
        self.engine = engine
        self.metadata = MetaData()
        self.inspector = inspect(engine)
        
    def get_current_tables(self) -> List[str]:
        """å–å¾—ç›®å‰è³‡æ–™åº«ä¸­çš„è¡¨æ ¼"""
        return self.inspector.get_table_names()
    
    def get_table_columns(self, table_name: str) -> Dict:
        """å–å¾—è¡¨æ ¼æ¬„ä½è³‡è¨Š"""
        try:
            columns = self.inspector.get_columns(table_name)
            return {col['name']: col for col in columns}
        except Exception as e:
            logger.warning(f"ç„¡æ³•å–å¾—è¡¨æ ¼ {table_name} çš„æ¬„ä½è³‡è¨Š: {e}")
            return {}
    
    def table_exists(self, table_name: str) -> bool:
        """æª¢æŸ¥è¡¨æ ¼æ˜¯å¦å­˜åœ¨"""
        return table_name in self.get_current_tables()
    
    def column_exists(self, table_name: str, column_name: str) -> bool:
        """æª¢æŸ¥æ¬„ä½æ˜¯å¦å­˜åœ¨"""
        if not self.table_exists(table_name):
            return False
        columns = self.get_table_columns(table_name)
        return column_name in columns
    
    def backup_database(self, backup_path: Optional[str] = None) -> str:
        """å‚™ä»½è³‡æ–™åº«"""
        if backup_path is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_path = f"backup_migration_{timestamp}.db"
        
        logger.info(f"æ­£åœ¨å‚™ä»½è³‡æ–™åº«åˆ°: {backup_path}")
        
        # SQLite å‚™ä»½
        if "sqlite" in DATABASE_URL.lower():
            import shutil
            db_file = DATABASE_URL.replace("sqlite:///./", "").replace("sqlite:///", "")
            if os.path.exists(db_file):
                shutil.copy2(db_file, backup_path)
                logger.info(f"âœ… è³‡æ–™åº«å‚™ä»½å®Œæˆ: {backup_path}")
                return backup_path
        
        logger.warning("âš ï¸ ç„¡æ³•è‡ªå‹•å‚™ä»½è³‡æ–™åº«ï¼Œè«‹æ‰‹å‹•å‚™ä»½")
        return ""
    
    def create_migration_info_table(self):
        """å‰µå»ºé·ç§»è³‡è¨Šè¡¨æ ¼"""
        with self.engine.connect() as conn:
            conn.execute(text("""
                CREATE TABLE IF NOT EXISTS migration_history (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    migration_name TEXT NOT NULL UNIQUE,
                    executed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                    description TEXT,
                    success BOOLEAN DEFAULT TRUE
                )
            """))
            conn.commit()
    
    def is_migration_executed(self, migration_name: str) -> bool:
        """æª¢æŸ¥é·ç§»æ˜¯å¦å·²åŸ·è¡Œ"""
        try:
            with self.engine.connect() as conn:
                result = conn.execute(
                    text("SELECT COUNT(*) FROM migration_history WHERE migration_name = :name AND success = 1"),
                    {"name": migration_name}
                )
                return result.scalar() > 0
        except:
            return False
    
    def record_migration(self, migration_name: str, description: str, success: bool = True):
        """è¨˜éŒ„é·ç§»åŸ·è¡Œç‹€æ…‹"""
        with self.engine.connect() as conn:
            conn.execute(text("""
                INSERT OR REPLACE INTO migration_history 
                (migration_name, description, success, executed_at) 
                VALUES (:name, :desc, :success, CURRENT_TIMESTAMP)
            """), {
                "name": migration_name,
                "desc": description,
                "success": success
            })
            conn.commit()
    
    def run_migration_001_initial_schema(self):
        """é·ç§» 001: åˆå§‹åŒ–è³‡æ–™åº«çµæ§‹"""
        migration_name = "001_initial_schema"
        description = "åˆå§‹åŒ–æ‰€æœ‰è³‡æ–™åº«è¡¨æ ¼çµæ§‹"
        
        if self.is_migration_executed(migration_name):
            logger.info(f"â­ï¸ é·ç§» {migration_name} å·²åŸ·è¡Œéï¼Œè·³é")
            return
        
        logger.info(f"ğŸš€ åŸ·è¡Œé·ç§»: {migration_name}")
        
        try:
            # å‰µå»ºæ‰€æœ‰è¡¨æ ¼
            Base.metadata.create_all(bind=self.engine)
            
            # é©—è­‰é‡è¦è¡¨æ ¼
            required_tables = [
                'teams', 'test_run_configs', 'test_run_items', 
                'test_run_item_result_history', 'tcg_records',
                'lark_departments', 'lark_users', 'sync_history'
            ]
            
            missing_tables = []
            for table in required_tables:
                if not self.table_exists(table):
                    missing_tables.append(table)
            
            if missing_tables:
                raise Exception(f"ä»¥ä¸‹è¡¨æ ¼å‰µå»ºå¤±æ•—: {missing_tables}")
            
            self.record_migration(migration_name, description, True)
            logger.info(f"âœ… é·ç§» {migration_name} å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ é·ç§» {migration_name} å¤±æ•—: {e}")
            self.record_migration(migration_name, f"{description} - å¤±æ•—: {e}", False)
            raise
    
    def run_migration_002_verify_columns(self):
        """é·ç§» 002: é©—è­‰é‡è¦æ¬„ä½"""
        migration_name = "002_verify_columns"
        description = "é©—è­‰æ‰€æœ‰é‡è¦æ¬„ä½å­˜åœ¨"
        
        if self.is_migration_executed(migration_name):
            logger.info(f"â­ï¸ é·ç§» {migration_name} å·²åŸ·è¡Œéï¼Œè·³é")
            return
        
        logger.info(f"ğŸ” åŸ·è¡Œé·ç§»: {migration_name}")
        
        try:
            # é©—è­‰é—œéµæ¬„ä½
            critical_fields = {
                'test_run_items': ['bug_tickets_json', 'assignee_json', 'tcg_json'],
                'test_run_configs': ['related_tp_tickets_json', 'tp_tickets_search'],
                'teams': ['wiki_token', 'test_case_table_id'],
                'lark_users': ['enterprise_email', 'primary_department_id'],
                'lark_departments': ['department_id', 'parent_department_id']
            }
            
            missing_fields = []
            for table_name, fields in critical_fields.items():
                if self.table_exists(table_name):
                    for field in fields:
                        if not self.column_exists(table_name, field):
                            missing_fields.append(f"{table_name}.{field}")
                else:
                    missing_fields.append(f"è¡¨æ ¼ {table_name} ä¸å­˜åœ¨")
            
            if missing_fields:
                logger.warning(f"âš ï¸ ç¼ºå°‘æ¬„ä½: {missing_fields}")
                # é€™è£¡å¯ä»¥æ ¹æ“šéœ€è¦æ·»åŠ ä¿®å¾©é‚è¼¯
            
            self.record_migration(migration_name, description, True)
            logger.info(f"âœ… é·ç§» {migration_name} å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ é·ç§» {migration_name} å¤±æ•—: {e}")
            self.record_migration(migration_name, f"{description} - å¤±æ•—: {e}", False)
            raise
    
    def run_migration_003_indexes_constraints(self):
        """é·ç§» 003: ç¢ºä¿ç´¢å¼•å’Œç´„æŸ"""
        migration_name = "003_indexes_constraints"
        description = "å‰µå»ºæ€§èƒ½ç´¢å¼•å’Œç´„æŸ"
        
        if self.is_migration_executed(migration_name):
            logger.info(f"â­ï¸ é·ç§» {migration_name} å·²åŸ·è¡Œéï¼Œè·³é")
            return
        
        logger.info(f"ğŸ“Š åŸ·è¡Œé·ç§»: {migration_name}")
        
        try:
            with self.engine.connect() as conn:
                # å‰µå»ºé‡è¦ç´¢å¼•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
                indexes = [
                    "CREATE INDEX IF NOT EXISTS ix_test_run_items_config_case ON test_run_items(config_id, test_case_number)",
                    "CREATE INDEX IF NOT EXISTS ix_test_run_items_team_result ON test_run_items(team_id, test_result)",
                    "CREATE INDEX IF NOT EXISTS ix_lark_users_email ON lark_users(enterprise_email)",
                    "CREATE INDEX IF NOT EXISTS ix_lark_users_dept ON lark_users(primary_department_id)",
                    "CREATE INDEX IF NOT EXISTS ix_sync_history_team_time ON sync_history(team_id, start_time)"
                ]
                
                for index_sql in indexes:
                    try:
                        conn.execute(text(index_sql))
                        logger.info(f"  âœ“ ç´¢å¼•å‰µå»º: {index_sql.split('ON')[1].split('(')[0].strip()}")
                    except Exception as e:
                        logger.warning(f"  âš ï¸ ç´¢å¼•å‰µå»ºè·³é: {e}")
                
                conn.commit()
            
            self.record_migration(migration_name, description, True)
            logger.info(f"âœ… é·ç§» {migration_name} å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ é·ç§» {migration_name} å¤±æ•—: {e}")
            self.record_migration(migration_name, f"{description} - å¤±æ•—: {e}", False)
            raise
    
    def get_database_stats(self) -> Dict:
        """å–å¾—è³‡æ–™åº«çµ±è¨ˆè³‡è¨Š"""
        stats = {
            'tables': len(self.get_current_tables()),
            'table_details': {}
        }
        
        for table in self.get_current_tables():
            try:
                with self.engine.connect() as conn:
                    result = conn.execute(text(f"SELECT COUNT(*) FROM {table}"))
                    count = result.scalar()
                    stats['table_details'][table] = {
                        'rows': count,
                        'columns': len(self.get_table_columns(table))
                    }
            except Exception as e:
                stats['table_details'][table] = {'error': str(e)}
        
        return stats
    
    def run_all_migrations(self):
        """åŸ·è¡Œæ‰€æœ‰é·ç§»"""
        logger.info("ğŸš€ é–‹å§‹è³‡æ–™åº«é·ç§»ç¨‹åº")
        
        # å‰µå»ºé·ç§»æ­·å²è¡¨æ ¼
        self.create_migration_info_table()
        
        # å‚™ä»½è³‡æ–™åº«
        backup_file = self.backup_database()
        
        try:
            # åŸ·è¡Œæ‰€æœ‰é·ç§»
            self.run_migration_001_initial_schema()
            self.run_migration_002_verify_columns()
            self.run_migration_003_indexes_constraints()
            
            # é¡¯ç¤ºæœ€çµ‚çµ±è¨ˆ
            stats = self.get_database_stats()
            logger.info("ğŸ“Š è³‡æ–™åº«çµ±è¨ˆ:")
            logger.info(f"  ç¸½è¡¨æ ¼æ•¸: {stats['tables']}")
            for table, details in stats['table_details'].items():
                if 'error' not in details:
                    logger.info(f"  {table}: {details['rows']} ç­†è¨˜éŒ„, {details['columns']} æ¬„ä½")
                else:
                    logger.warning(f"  {table}: éŒ¯èª¤ - {details['error']}")
            
            logger.info("ğŸ‰ æ‰€æœ‰é·ç§»å®Œæˆ!")
            
        except Exception as e:
            logger.error(f"ğŸ’¥ é·ç§»éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤: {e}")
            if backup_file and os.path.exists(backup_file):
                logger.info(f"ğŸ”„ å¯ä½¿ç”¨å‚™ä»½æª”æ¡ˆæ¢å¾©: {backup_file}")
            raise

def main():
    """ä¸»å‡½æ•¸"""
    print("=" * 50)
    print("ğŸ—ƒï¸  è³‡æ–™åº«é·ç§»ç³»çµ± v2.0")
    print("=" * 50)
    
    migrator = DatabaseMigrator(engine)
    
    try:
        migrator.run_all_migrations()
        print("\nâœ… é·ç§»ç¨‹åºæˆåŠŸå®Œæˆ!")
        print(f"ğŸ“‚ è³‡æ–™åº«ä½ç½®: {DATABASE_URL}")
        
    except Exception as e:
        print(f"\nâŒ é·ç§»ç¨‹åºå¤±æ•—: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()