#!/usr/bin/env python3
"""
æ¸¬è©¦ Lark API æ‰¹æ¬¡æ›´æ–°åŠŸèƒ½
ç¢ºèª API ç«¯é»æ˜¯å¦å­˜åœ¨åŠå…¶è«‹æ±‚æ ¼å¼
"""
import os
import sys
import json
import logging
from pathlib import Path
from typing import List, Dict, Any, Optional

# åŠ å…¥å°ˆæ¡ˆè·¯å¾‘
sys.path.insert(0, str(Path(__file__).parent))

from app.services.lark_client import LarkClient
from app.config import settings
from app.database import get_db
from app.models.database_models import Team

# è¨­å®šæ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class LarkBatchUpdateTester:
    """Lark æ‰¹æ¬¡æ›´æ–°æ¸¬è©¦å™¨"""
    
    def __init__(self):
        self.client = LarkClient(
            app_id=settings.lark.app_id,
            app_secret=settings.lark.app_secret
        )
        self.test_results = {
            'batch_update_supported': False,
            'api_endpoint': None,
            'http_method': None,
            'request_format': None,
            'max_batch_size': None,
            'error_messages': []
        }
    
    def get_test_team_and_table(self) -> tuple[Optional[str], Optional[str]]:
        """å–å¾—æ¸¬è©¦ç”¨çš„åœ˜éšŠå’Œè¡¨æ ¼ ID"""
        try:
            db = next(get_db())
            teams = db.query(Team).filter(Team.test_case_table_id.isnot(None)).limit(1).all()
            if teams:
                team = teams[0]
                # ç›´æ¥ä½¿ç”¨è³‡æ–™åº«ä¸­çš„ wiki_token å’Œ table_id
                if team.wiki_token and team.test_case_table_id:
                    obj_token = team.wiki_token
                    table_id = team.test_case_table_id
                    logger.info(f"æ‰¾åˆ°æ¸¬è©¦åœ˜éšŠ: {team.name}")
                    logger.info(f"Obj Token: {obj_token}")
                    logger.info(f"Table ID: {table_id}")
                    return obj_token, table_id
            
            logger.warning("æœªæ‰¾åˆ°å¯ç”¨çš„æ¸¬è©¦åœ˜éšŠæˆ–ç„¡æ³•è§£æè¡¨æ ¼è³‡è¨Š")
            return None, None
            
        except Exception as e:
            logger.error(f"å–å¾—æ¸¬è©¦åœ˜éšŠå¤±æ•—: {e}")
            return None, None
    
    def get_sample_records(self, obj_token: str, table_id: str, limit: int = 2) -> List[Dict[str, Any]]:
        """å–å¾—æ¨£æœ¬è¨˜éŒ„ç”¨æ–¼æ¸¬è©¦"""
        try:
            # ä½¿ç”¨æ­£ç¢ºçš„æ–¹å¼è¨­ç½® wiki_token
            if not self.client.set_wiki_token(obj_token):
                logger.error("ç„¡æ³•è¨­å®š wiki_token")
                return []
            records = self.client.get_all_records(table_id)
            if records and len(records) >= limit:
                sample_records = records[:limit]
                logger.info(f"å–å¾— {len(sample_records)} ç­†æ¨£æœ¬è¨˜éŒ„")
                return sample_records
            else:
                logger.warning(f"è¨˜éŒ„æ•¸é‡ä¸è¶³ï¼Œåƒ…æœ‰ {len(records) if records else 0} ç­†")
                return records[:limit] if records else []
                
        except Exception as e:
            logger.error(f"å–å¾—æ¨£æœ¬è¨˜éŒ„å¤±æ•—: {e}")
            return []
    
    def create_test_updates(self, sample_records: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """å»ºç«‹æ¸¬è©¦ç”¨çš„æ›´æ–°è³‡æ–™"""
        updates = []
        
        for i, record in enumerate(sample_records):
            record_id = record.get('record_id')
            if not record_id:
                continue
                
            # å»ºç«‹æ¸¬è©¦æ›´æ–°è³‡æ–™ï¼ˆåƒ…æ›´æ–°å®‰å…¨çš„æ¬„ä½ï¼‰
            test_update = {
                'record_id': record_id,
                'fields': {
                    # åƒ…æ›´æ–°è¨»è§£æ¬„ä½ï¼Œé¿å…å½±éŸ¿é‡è¦è³‡æ–™
                    'fldvQT4eUb': f'[æ¸¬è©¦] æ‰¹æ¬¡æ›´æ–°æ¸¬è©¦ #{i+1} - {json.dumps({"timestamp": "test", "batch_update": True})}'
                }
            }
            updates.append(test_update)
        
        logger.info(f"å»ºç«‹ {len(updates)} ç­†æ¸¬è©¦æ›´æ–°è³‡æ–™")
        return updates
    
    def test_batch_update_endpoint(self, obj_token: str, table_id: str, updates: List[Dict[str, Any]]) -> bool:
        """æ¸¬è©¦æ‰¹æ¬¡æ›´æ–°ç«¯é»"""
        test_scenarios = [
            {
                'method': 'POST',
                'endpoint': f"/bitable/v1/apps/{obj_token}/tables/{table_id}/records/batch_update",
                'data_format': {'records': updates}
            },
            {
                'method': 'PUT', 
                'endpoint': f"/bitable/v1/apps/{obj_token}/tables/{table_id}/records/batch_update",
                'data_format': {'records': updates}
            },
            {
                'method': 'PATCH',
                'endpoint': f"/bitable/v1/apps/{obj_token}/tables/{table_id}/records/batch_update", 
                'data_format': {'records': updates}
            }
        ]
        
        for scenario in test_scenarios:
            logger.info(f"æ¸¬è©¦ {scenario['method']} {scenario['endpoint']}")
            
            try:
                url = self.client.record_manager.base_url + scenario['endpoint']
                
                # ä½¿ç”¨ Record Manager çš„ _make_request æ–¹æ³•
                if scenario['method'] == 'POST':
                    response = self.client.record_manager._make_request('POST', url, json=scenario['data_format'])
                elif scenario['method'] == 'PUT':
                    response = self.client.record_manager._make_request('PUT', url, json=scenario['data_format'])
                elif scenario['method'] == 'PATCH':
                    response = self.client.record_manager._make_request('PATCH', url, json=scenario['data_format'])
                
                if response:
                    logger.info(f"âœ… æˆåŠŸï¼{scenario['method']} æ–¹æ³•æœ‰æ•ˆ")
                    logger.info(f"å›æ‡‰: {json.dumps(response, indent=2, ensure_ascii=False)}")
                    
                    # è¨˜éŒ„æˆåŠŸçš„é…ç½®
                    self.test_results.update({
                        'batch_update_supported': True,
                        'api_endpoint': scenario['endpoint'],
                        'http_method': scenario['method'],
                        'request_format': scenario['data_format'],
                        'max_batch_size': len(updates)
                    })
                    return True
                    
            except Exception as e:
                error_msg = f"{scenario['method']} å¤±æ•—: {str(e)}"
                logger.warning(error_msg)
                self.test_results['error_messages'].append(error_msg)
                continue
        
        return False
    
    def test_batch_size_limits(self, obj_token: str, table_id: str, base_update: Dict[str, Any]) -> int:
        """æ¸¬è©¦æ‰¹æ¬¡å¤§å°é™åˆ¶"""
        if not self.test_results['batch_update_supported']:
            return 0
        
        test_sizes = [1, 10, 50, 100, 500, 1000]
        max_working_size = 0
        
        for size in test_sizes:
            logger.info(f"æ¸¬è©¦æ‰¹æ¬¡å¤§å°: {size}")
            
            # å»ºç«‹æ¸¬è©¦è³‡æ–™
            test_updates = []
            for i in range(size):
                update = {
                    'record_id': base_update['record_id'],  # ä½¿ç”¨ç›¸åŒè¨˜éŒ„ID
                    'fields': {
                        'fldvQT4eUb': f'[æ¸¬è©¦] æ‰¹æ¬¡å¤§å°æ¸¬è©¦ {size} ç­† #{i+1}'
                    }
                }
                test_updates.append(update)
            
            try:
                url = self.client.record_manager.base_url + self.test_results['api_endpoint']
                data = {'records': test_updates}
                response = self.client.record_manager._make_request(self.test_results['http_method'], url, json=data)
                
                if response:
                    max_working_size = size
                    logger.info(f"âœ… æ‰¹æ¬¡å¤§å° {size} æ¸¬è©¦æˆåŠŸ")
                else:
                    logger.warning(f"âŒ æ‰¹æ¬¡å¤§å° {size} æ¸¬è©¦å¤±æ•—")
                    break
                    
            except Exception as e:
                logger.warning(f"âŒ æ‰¹æ¬¡å¤§å° {size} æ¸¬è©¦å¤±æ•—: {e}")
                break
        
        self.test_results['max_batch_size'] = max_working_size
        return max_working_size
    
    def rollback_test_changes(self, obj_token: str, table_id: str, original_records: List[Dict[str, Any]]):
        """å›æ»¾æ¸¬è©¦è®Šæ›´"""
        logger.info("é–‹å§‹å›æ»¾æ¸¬è©¦è®Šæ›´...")
        
        try:
            rollback_updates = []
            for record in original_records:
                record_id = record.get('record_id')
                fields = record.get('fields', {})
                
                if record_id and 'fldvQT4eUb' in fields:
                    rollback_updates.append({
                        'record_id': record_id,
                        'fields': {
                            'fldvQT4eUb': fields['fldvQT4eUb']  # æ¢å¾©åŸå§‹å€¼
                        }
                    })
            
            if rollback_updates and self.test_results['batch_update_supported']:
                url = self.client.record_manager.base_url + self.test_results['api_endpoint']
                data = {'records': rollback_updates}
                response = self.client.record_manager._make_request(self.test_results['http_method'], url, json=data)
                
                if response:
                    logger.info("âœ… æ¸¬è©¦è®Šæ›´å›æ»¾æˆåŠŸ")
                else:
                    logger.warning("âš ï¸ æ¸¬è©¦è®Šæ›´å›æ»¾å¤±æ•—ï¼Œè«‹æ‰‹å‹•æª¢æŸ¥")
            else:
                logger.info("ç„¡éœ€å›æ»¾æˆ–æ‰¹æ¬¡æ›´æ–°ä¸æ”¯æ´")
                
        except Exception as e:
            logger.error(f"å›æ»¾æ¸¬è©¦è®Šæ›´å¤±æ•—: {e}")
    
    def run_full_test(self) -> Dict[str, Any]:
        """åŸ·è¡Œå®Œæ•´æ¸¬è©¦"""
        logger.info("é–‹å§‹ Lark API æ‰¹æ¬¡æ›´æ–°æ¸¬è©¦")
        logger.info("=" * 60)
        
        # 1. å–å¾—æ¸¬è©¦ç’°å¢ƒ
        obj_token, table_id = self.get_test_team_and_table()
        if not obj_token or not table_id:
            self.test_results['error_messages'].append("ç„¡æ³•å–å¾—æ¸¬è©¦ç’°å¢ƒ")
            return self.test_results
        
        # 2. å–å¾—æ¨£æœ¬è¨˜éŒ„
        sample_records = self.get_sample_records(obj_token, table_id, limit=3)
        if not sample_records:
            self.test_results['error_messages'].append("ç„¡æ³•å–å¾—æ¨£æœ¬è¨˜éŒ„")
            return self.test_results
        
        # ä¿å­˜åŸå§‹è¨˜éŒ„ç”¨æ–¼å›æ»¾
        original_records = [record.copy() for record in sample_records]
        
        # 3. å»ºç«‹æ¸¬è©¦æ›´æ–°
        test_updates = self.create_test_updates(sample_records)
        if not test_updates:
            self.test_results['error_messages'].append("ç„¡æ³•å»ºç«‹æ¸¬è©¦æ›´æ–°è³‡æ–™")
            return self.test_results
        
        try:
            # 4. æ¸¬è©¦æ‰¹æ¬¡æ›´æ–°ç«¯é»
            logger.info("æ­¥é©Ÿ 1: æ¸¬è©¦æ‰¹æ¬¡æ›´æ–° API ç«¯é»")
            if self.test_batch_update_endpoint(obj_token, table_id, test_updates):
                logger.info("âœ… æ‰¹æ¬¡æ›´æ–° API å­˜åœ¨ä¸”å¯ç”¨")
                
                # 5. æ¸¬è©¦æ‰¹æ¬¡å¤§å°é™åˆ¶
                logger.info("æ­¥é©Ÿ 2: æ¸¬è©¦æ‰¹æ¬¡å¤§å°é™åˆ¶")
                max_size = self.test_batch_size_limits(obj_token, table_id, test_updates[0])
                logger.info(f"æœ€å¤§æ‰¹æ¬¡å¤§å°: {max_size}")
                
            else:
                logger.info("âŒ æ‰¹æ¬¡æ›´æ–° API ä¸å­˜åœ¨æˆ–ä¸å¯ç”¨")
                
        finally:
            # 6. å›æ»¾æ¸¬è©¦è®Šæ›´
            self.rollback_test_changes(obj_token, table_id, original_records)
        
        return self.test_results

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ§ª Lark API æ‰¹æ¬¡æ›´æ–°æ¸¬è©¦è…³æœ¬")
    print("=" * 60)
    
    try:
        tester = LarkBatchUpdateTester()
        results = tester.run_full_test()
        
        # è¼¸å‡ºæ¸¬è©¦çµæœ
        print("\nğŸ“Š æ¸¬è©¦çµæœæ‘˜è¦")
        print("=" * 60)
        
        if results['batch_update_supported']:
            print("âœ… Lark æ”¯æ´æ‰¹æ¬¡æ›´æ–°åŠŸèƒ½")
            print(f"ğŸ“¡ API ç«¯é»: {results['api_endpoint']}")
            print(f"ğŸ”§ HTTP æ–¹æ³•: {results['http_method']}")
            print(f"ğŸ“¦ æœ€å¤§æ‰¹æ¬¡å¤§å°: {results['max_batch_size']}")
            print(f"ğŸ“‹ è«‹æ±‚æ ¼å¼: {json.dumps(results['request_format'], indent=2, ensure_ascii=False)}")
            
            print("\nğŸš€ å»ºè­°å¯¦ä½œ:")
            print("1. åœ¨ lark_client.py ä¸­å¯¦ä½œ batch_update_records æ–¹æ³•")
            print("2. ä½¿ç”¨ä¸Šè¿° API ç«¯é»å’Œè«‹æ±‚æ ¼å¼")
            print("3. æ‰¹æ¬¡è™•ç†æ™‚æ¯æ‰¹ä¸è¶…é", results['max_batch_size'], "ç­†è¨˜éŒ„")
            print("4. é æœŸæ•ˆèƒ½æå‡: 10-50 å€")
            
        else:
            print("âŒ Lark ä¸æ”¯æ´æ‰¹æ¬¡æ›´æ–°åŠŸèƒ½")
            print("ğŸ”§ å»ºè­°å„ªåŒ–æ–¹æ¡ˆ:")
            print("1. ä½¿ç”¨ä¸¦è¡Œè™•ç†å„ªåŒ–é€ç­†æ›´æ–°")
            print("2. å¯¦ä½œæ™ºæ…§é‡è©¦æ©Ÿåˆ¶")
            print("3. å¢åŠ é€²åº¦æç¤ºæ”¹å–„ä½¿ç”¨è€…é«”é©—")
            print("4. é æœŸæ•ˆèƒ½æå‡: 3-5 å€")
        
        if results['error_messages']:
            print("\nâš ï¸ æ¸¬è©¦éç¨‹ä¸­çš„éŒ¯èª¤:")
            for error in results['error_messages']:
                print(f"  - {error}")
        
        print("\n" + "=" * 60)
        return 0 if results['batch_update_supported'] else 1
        
    except Exception as e:
        logger.error(f"æ¸¬è©¦åŸ·è¡Œå¤±æ•—: {e}")
        print(f"\nğŸ’¥ æ¸¬è©¦å¤±æ•—: {e}")
        return 2

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)